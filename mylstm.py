from __future__ import division, print_function, absolute_import
import numpy as np
import tflearn
from tflearn.data_utils import to_categorical, pad_sequences
import sklearn
from sklearn.model_selection import train_test_split
import mydata as data

def build_model(max_features, maxlen):
	"""Build LSTM model"""
	# model = Sequential()
	# model.add(Embedding(max_features, 128, input_length=maxlen))
	# model.add(LSTM(128))
	# model.add(Dropout(0.5))
	# model.add(Dense(1))
	# model.add(Activation('sigmoid'))

	# model.compile(loss='binary_crossentropy',
	#               optimizer='rmsprop')

	net = tflearn.input_data([None, 5548])
	net = tflearn.embedding(net, input_dim=10000, output_dim=128)
	net = tflearn.lstm(net, 128, dropout=0.8)
	net = tflearn.fully_connected(net, 2, activation='softmax')
	net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,
						 loss='categorical_crossentropy')

	# Training
	model = tflearn.DNN(net, tensorboard_verbose=0)
	return model


def run(max_epoch=25, nfolds=10, batch_size=128):
	"""Run train/test on logistic regression model"""
	indata = data.get_data()

	# Extract data and labels
	X = [x[1] for x in indata]
	labels = [x[0] for x in indata]

	# Generate a dictionary of valid characters
	valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X)))}

	max_features = len(valid_chars) + 1
	maxlen = np.max([len(x) for x in X])
	X = X[:100]
	labels = labels[:100]

	# Convert characters to int and pad
	X = [[valid_chars[y] for y in x] for x in X]
	X = pad_sequences(X, maxlen=maxlen)

	# Convert labels to 0-1
	y = [0 if x == 'benign' else 1 for x in labels]

	final_data = []
	
	for fold in range(nfolds):
		print("fold %u/%u" % (fold+1, nfolds))
		X_train, X_test, y_train, y_test, _, label_test = train_test_split(X, y, labels, 
																		   test_size=0.2)

		print('Build model...')
		model = build_model(max_features, maxlen)

		print("Train...")
		X_train, X_holdout, y_train, y_holdout = train_test_split(X_train, y_train, test_size=0.05)
		best_iter = -1
		best_auc = 0.0
		out_data = {}
		X_train = X_train.reshape(1,5548)
		for ep in range(max_epoch):
			model.fit(X_train, y_train, batch_size=batch_size,validation_set=(X_test, y_test), show_metric=True, n_epoch=1)

			t_probs = model.predict(X_holdout)
			t_auc = sklearn.metrics.roc_auc_score(y_holdout, t_probs)

			print('Epoch %d: auc = %f (best=%f)' % (ep, t_auc, best_auc))

			if t_auc > best_auc:
				best_auc = t_auc
				best_iter = ep

				probs = model.predict_proba(X_test)

				out_data = {'y':y_test, 'labels': label_test, 'probs':probs, 'epochs': ep,
							'confusion_matrix': sklearn.metrics.confusion_matrix(y_test, probs > .5)}

				print(sklearn.metrics.confusion_matrix(y_test, probs > .5))
			else:
				# No longer improving...break and calc statistics
				if (ep-best_iter) > 2:
					break

		final_data.append(out_data)
		print('Saving model')
		model.save('my_model.tflearn')

	return final_data
